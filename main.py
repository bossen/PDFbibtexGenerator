#!/bin/python2
from pyPdf import PdfFileWriter, PdfFileReader
from BeautifulSoup import BeautifulSoup
from urlparse import urlparse
import glob, os, StringIO, re, urllib, webbrowser, requests, argparse

__version__ = "0.1"

def get_pdf_title(pdf_file_path, titleLength):
    with open(pdf_file_path) as f:
        pdf_reader = PdfFileReader(f) 

        title = pdf_reader.getDocumentInfo().title

        if title and "dvi" not in title:
            return title
        content = pdf_reader.getPage(0).extractText()
        return re.sub(r"(\w)([A-Z])", r"\1 \2", content[:titleLength]).rsplit(' ', 1)[0]

def get_pdf_files(path="./"):
    os.chdir(path)
    res = glob.glob("*.pdf")
    if len(res) == 0:
        print "No pdf files found!"
    return res

def get_dblp_page(title):
    #At the moment we are not allowed to scrape google pages
    url = "https://google.com/search?&btnI=I&q=site:dblp.uni-trier.de+%s" % title.replace(' ', '+')

    webbrowser.open(url)

    dblp = raw_input("insert dblp url: ")
    return dblp if dblp else None

def get_bibTex(title, url):
    r = requests.get(url)
    soup = BeautifulSoup(r.text)

    bib_url = ""

    if urlparse(url).hostname == "dblp.uni-trier.de":
        bib_url = get_bibTexFromDblp(title, soup)

    if bib_url:
        r = requests.get(bib_url)
        return r.text
    return None

def noSpaceLowerCase(s):
    return s.replace(' ', '').lower()

def compareTitles(s1, s2):
    return noSpaceLowerCase(s1) in noSpaceLowerCase(s2)

def get_bibTexFromDblp(title, soup):
    #Should be one command
    #soup.findAll('li', {'class': 'entry editor'})
    #soup.findAll('li', {'class': 'entry article'})
    url = ""
    for e in soup.findAll('li', {'class': 'entry inproceedings'}):
        e_title = e.find('span', {'class': 'title'}).text
        if compareTitles(title, e_title):
            for a in e.findAll('a'):
                if "bibtex" in a['href']:
                    return a['href'].replace("bibtex", "bib2") + ".bib"



def getParser(parser):
    parser.add_argument('dir', nargs='?', help='location with pdf files. If empty using current dir')
    parser.add_argument('-O', '--output', help='output file default=bibliography.bib')
    args = parser.parse_args()
    return args

def main():
    parser = argparse.ArgumentParser()
    args = getParser(parser)

    filePath = args.dir if args.dir else "./"
    filename = args.output if args.output else "bibliography.bib"

    bibtex = open(filename, "w")
    bibtex.write("Pseudo-autogenerated using PDF bibtex generator version %s\n\n" %  __version__)

    for f in get_pdf_files(filePath):
        bibtex.write("Generated from %s\n" % f)
        title = get_pdf_title(f, 50)
        url = get_dblp_page(title)

        if url:
            content = get_bibTex(title, url)
            if content:
                bibtex.write(content)
                continue

        # not possible to find bibtex
        bibtex.write(
"""@ARTICLE{TODO,
author    = TODO,
title     = %s,
journal   = TODO,
year      = TODO,
}\n
"""
        % title)

    bibtex.close()

if __name__ == "__main__":
    main()
